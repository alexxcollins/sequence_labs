{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2607e9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############################################   LAB 6   ##############################################\n",
      "################### Script written by Dr Alex Ter-Sarkisov@City, University of London, 2022 ############\n",
      "##################### DEEP LEARNING FOR SEQUENCE ANALYSIS, MSC IN ARTIFICIAL INTELLIGENCE ##############\n",
      "########################################################################################################\n"
     ]
    }
   ],
   "source": [
    "print('###############################################   LAB 6   ##############################################')\n",
    "print('################### Script written by Dr Alex Ter-Sarkisov@City, University of London, 2022 ############')\n",
    "print('##################### DEEP LEARNING FOR SEQUENCE ANALYSIS, MSC IN ARTIFICIAL INTELLIGENCE ##############')\n",
    "print('########################################################################################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29c2c233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import net_ucf11\n",
    "from PIL import Image as Image\n",
    "from torchvision import transforms, utils, models\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data as data\n",
    "import dataset_ucf11\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torch.utils.model_zoo import load_url as load_state_dict_from_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eab6243e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to cpu\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (18): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (19): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (20): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (21): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (22): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "  (out_fc): Linear(in_features=2048, out_features=512, bias=True)\n",
      ")\n",
      "DecoderRNN(\n",
      "  (LSTM): LSTM(512, 256, num_layers=3, batch_first=True)\n",
      "  (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=11, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "   device = torch.device('cuda')\n",
    "\n",
    "print ('Device set to {0}'.format(device))\n",
    "\n",
    "epoch = 10\n",
    "learning_rate = 1e-6\n",
    "#batch size: number of data samples in the current batch\n",
    "sample_size = 2\n",
    "# ResNet101\n",
    "feature_extractor_base = net_ucf11.resnet101(fc_layer=False, zero_init_residual=True)\n",
    "# LSTM\n",
    "rnn = net_ucf11.rnn_model()\n",
    "\n",
    "print(feature_extractor_base)\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02f51942",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying weights into conv1.weight\n",
      "Copying weights into bn1.running_mean\n",
      "Copying weights into bn1.running_var\n",
      "Copying weights into bn1.weight\n",
      "Copying weights into bn1.bias\n",
      "Copying weights into layer1.0.conv1.weight\n",
      "Copying weights into layer1.0.bn1.running_mean\n",
      "Copying weights into layer1.0.bn1.running_var\n",
      "Copying weights into layer1.0.bn1.weight\n",
      "Copying weights into layer1.0.bn1.bias\n",
      "Copying weights into layer1.0.conv2.weight\n",
      "Copying weights into layer1.0.bn2.running_mean\n",
      "Copying weights into layer1.0.bn2.running_var\n",
      "Copying weights into layer1.0.bn2.weight\n",
      "Copying weights into layer1.0.bn2.bias\n",
      "Copying weights into layer1.0.conv3.weight\n",
      "Copying weights into layer1.0.bn3.running_mean\n",
      "Copying weights into layer1.0.bn3.running_var\n",
      "Copying weights into layer1.0.bn3.weight\n",
      "Copying weights into layer1.0.bn3.bias\n",
      "Copying weights into layer1.0.downsample.0.weight\n",
      "Copying weights into layer1.0.downsample.1.running_mean\n",
      "Copying weights into layer1.0.downsample.1.running_var\n",
      "Copying weights into layer1.0.downsample.1.weight\n",
      "Copying weights into layer1.0.downsample.1.bias\n",
      "Copying weights into layer1.1.conv1.weight\n",
      "Copying weights into layer1.1.bn1.running_mean\n",
      "Copying weights into layer1.1.bn1.running_var\n",
      "Copying weights into layer1.1.bn1.weight\n",
      "Copying weights into layer1.1.bn1.bias\n",
      "Copying weights into layer1.1.conv2.weight\n",
      "Copying weights into layer1.1.bn2.running_mean\n",
      "Copying weights into layer1.1.bn2.running_var\n",
      "Copying weights into layer1.1.bn2.weight\n",
      "Copying weights into layer1.1.bn2.bias\n",
      "Copying weights into layer1.1.conv3.weight\n",
      "Copying weights into layer1.1.bn3.running_mean\n",
      "Copying weights into layer1.1.bn3.running_var\n",
      "Copying weights into layer1.1.bn3.weight\n",
      "Copying weights into layer1.1.bn3.bias\n",
      "Copying weights into layer1.2.conv1.weight\n",
      "Copying weights into layer1.2.bn1.running_mean\n",
      "Copying weights into layer1.2.bn1.running_var\n",
      "Copying weights into layer1.2.bn1.weight\n",
      "Copying weights into layer1.2.bn1.bias\n",
      "Copying weights into layer1.2.conv2.weight\n",
      "Copying weights into layer1.2.bn2.running_mean\n",
      "Copying weights into layer1.2.bn2.running_var\n",
      "Copying weights into layer1.2.bn2.weight\n",
      "Copying weights into layer1.2.bn2.bias\n",
      "Copying weights into layer1.2.conv3.weight\n",
      "Copying weights into layer1.2.bn3.running_mean\n",
      "Copying weights into layer1.2.bn3.running_var\n",
      "Copying weights into layer1.2.bn3.weight\n",
      "Copying weights into layer1.2.bn3.bias\n",
      "Copying weights into layer2.0.conv1.weight\n",
      "Copying weights into layer2.0.bn1.running_mean\n",
      "Copying weights into layer2.0.bn1.running_var\n",
      "Copying weights into layer2.0.bn1.weight\n",
      "Copying weights into layer2.0.bn1.bias\n",
      "Copying weights into layer2.0.conv2.weight\n",
      "Copying weights into layer2.0.bn2.running_mean\n",
      "Copying weights into layer2.0.bn2.running_var\n",
      "Copying weights into layer2.0.bn2.weight\n",
      "Copying weights into layer2.0.bn2.bias\n",
      "Copying weights into layer2.0.conv3.weight\n",
      "Copying weights into layer2.0.bn3.running_mean\n",
      "Copying weights into layer2.0.bn3.running_var\n",
      "Copying weights into layer2.0.bn3.weight\n",
      "Copying weights into layer2.0.bn3.bias\n",
      "Copying weights into layer2.0.downsample.0.weight\n",
      "Copying weights into layer2.0.downsample.1.running_mean\n",
      "Copying weights into layer2.0.downsample.1.running_var\n",
      "Copying weights into layer2.0.downsample.1.weight\n",
      "Copying weights into layer2.0.downsample.1.bias\n",
      "Copying weights into layer2.1.conv1.weight\n",
      "Copying weights into layer2.1.bn1.running_mean\n",
      "Copying weights into layer2.1.bn1.running_var\n",
      "Copying weights into layer2.1.bn1.weight\n",
      "Copying weights into layer2.1.bn1.bias\n",
      "Copying weights into layer2.1.conv2.weight\n",
      "Copying weights into layer2.1.bn2.running_mean\n",
      "Copying weights into layer2.1.bn2.running_var\n",
      "Copying weights into layer2.1.bn2.weight\n",
      "Copying weights into layer2.1.bn2.bias\n",
      "Copying weights into layer2.1.conv3.weight\n",
      "Copying weights into layer2.1.bn3.running_mean\n",
      "Copying weights into layer2.1.bn3.running_var\n",
      "Copying weights into layer2.1.bn3.weight\n",
      "Copying weights into layer2.1.bn3.bias\n",
      "Copying weights into layer2.2.conv1.weight\n",
      "Copying weights into layer2.2.bn1.running_mean\n",
      "Copying weights into layer2.2.bn1.running_var\n",
      "Copying weights into layer2.2.bn1.weight\n",
      "Copying weights into layer2.2.bn1.bias\n",
      "Copying weights into layer2.2.conv2.weight\n",
      "Copying weights into layer2.2.bn2.running_mean\n",
      "Copying weights into layer2.2.bn2.running_var\n",
      "Copying weights into layer2.2.bn2.weight\n",
      "Copying weights into layer2.2.bn2.bias\n",
      "Copying weights into layer2.2.conv3.weight\n",
      "Copying weights into layer2.2.bn3.running_mean\n",
      "Copying weights into layer2.2.bn3.running_var\n",
      "Copying weights into layer2.2.bn3.weight\n",
      "Copying weights into layer2.2.bn3.bias\n",
      "Copying weights into layer2.3.conv1.weight\n",
      "Copying weights into layer2.3.bn1.running_mean\n",
      "Copying weights into layer2.3.bn1.running_var\n",
      "Copying weights into layer2.3.bn1.weight\n",
      "Copying weights into layer2.3.bn1.bias\n",
      "Copying weights into layer2.3.conv2.weight\n",
      "Copying weights into layer2.3.bn2.running_mean\n",
      "Copying weights into layer2.3.bn2.running_var\n",
      "Copying weights into layer2.3.bn2.weight\n",
      "Copying weights into layer2.3.bn2.bias\n",
      "Copying weights into layer2.3.conv3.weight\n",
      "Copying weights into layer2.3.bn3.running_mean\n",
      "Copying weights into layer2.3.bn3.running_var\n",
      "Copying weights into layer2.3.bn3.weight\n",
      "Copying weights into layer2.3.bn3.bias\n",
      "Copying weights into layer3.0.conv1.weight\n",
      "Copying weights into layer3.0.bn1.running_mean\n",
      "Copying weights into layer3.0.bn1.running_var\n",
      "Copying weights into layer3.0.bn1.weight\n",
      "Copying weights into layer3.0.bn1.bias\n",
      "Copying weights into layer3.0.conv2.weight\n",
      "Copying weights into layer3.0.bn2.running_mean\n",
      "Copying weights into layer3.0.bn2.running_var\n",
      "Copying weights into layer3.0.bn2.weight\n",
      "Copying weights into layer3.0.bn2.bias\n",
      "Copying weights into layer3.0.conv3.weight\n",
      "Copying weights into layer3.0.bn3.running_mean\n",
      "Copying weights into layer3.0.bn3.running_var\n",
      "Copying weights into layer3.0.bn3.weight\n",
      "Copying weights into layer3.0.bn3.bias\n",
      "Copying weights into layer3.0.downsample.0.weight\n",
      "Copying weights into layer3.0.downsample.1.running_mean\n",
      "Copying weights into layer3.0.downsample.1.running_var\n",
      "Copying weights into layer3.0.downsample.1.weight\n",
      "Copying weights into layer3.0.downsample.1.bias\n",
      "Copying weights into layer3.1.conv1.weight\n",
      "Copying weights into layer3.1.bn1.running_mean\n",
      "Copying weights into layer3.1.bn1.running_var\n",
      "Copying weights into layer3.1.bn1.weight\n",
      "Copying weights into layer3.1.bn1.bias\n",
      "Copying weights into layer3.1.conv2.weight\n",
      "Copying weights into layer3.1.bn2.running_mean\n",
      "Copying weights into layer3.1.bn2.running_var\n",
      "Copying weights into layer3.1.bn2.weight\n",
      "Copying weights into layer3.1.bn2.bias\n",
      "Copying weights into layer3.1.conv3.weight\n",
      "Copying weights into layer3.1.bn3.running_mean\n",
      "Copying weights into layer3.1.bn3.running_var\n",
      "Copying weights into layer3.1.bn3.weight\n",
      "Copying weights into layer3.1.bn3.bias\n",
      "Copying weights into layer3.2.conv1.weight\n",
      "Copying weights into layer3.2.bn1.running_mean\n",
      "Copying weights into layer3.2.bn1.running_var\n",
      "Copying weights into layer3.2.bn1.weight\n",
      "Copying weights into layer3.2.bn1.bias\n",
      "Copying weights into layer3.2.conv2.weight\n",
      "Copying weights into layer3.2.bn2.running_mean\n",
      "Copying weights into layer3.2.bn2.running_var\n",
      "Copying weights into layer3.2.bn2.weight\n",
      "Copying weights into layer3.2.bn2.bias\n",
      "Copying weights into layer3.2.conv3.weight\n",
      "Copying weights into layer3.2.bn3.running_mean\n",
      "Copying weights into layer3.2.bn3.running_var\n",
      "Copying weights into layer3.2.bn3.weight\n",
      "Copying weights into layer3.2.bn3.bias\n",
      "Copying weights into layer3.3.conv1.weight\n",
      "Copying weights into layer3.3.bn1.running_mean\n",
      "Copying weights into layer3.3.bn1.running_var\n",
      "Copying weights into layer3.3.bn1.weight\n",
      "Copying weights into layer3.3.bn1.bias\n",
      "Copying weights into layer3.3.conv2.weight\n",
      "Copying weights into layer3.3.bn2.running_mean\n",
      "Copying weights into layer3.3.bn2.running_var\n",
      "Copying weights into layer3.3.bn2.weight\n",
      "Copying weights into layer3.3.bn2.bias\n",
      "Copying weights into layer3.3.conv3.weight\n",
      "Copying weights into layer3.3.bn3.running_mean\n",
      "Copying weights into layer3.3.bn3.running_var\n",
      "Copying weights into layer3.3.bn3.weight\n",
      "Copying weights into layer3.3.bn3.bias\n",
      "Copying weights into layer3.4.conv1.weight\n",
      "Copying weights into layer3.4.bn1.running_mean\n",
      "Copying weights into layer3.4.bn1.running_var\n",
      "Copying weights into layer3.4.bn1.weight\n",
      "Copying weights into layer3.4.bn1.bias\n",
      "Copying weights into layer3.4.conv2.weight\n",
      "Copying weights into layer3.4.bn2.running_mean\n",
      "Copying weights into layer3.4.bn2.running_var\n",
      "Copying weights into layer3.4.bn2.weight\n",
      "Copying weights into layer3.4.bn2.bias\n",
      "Copying weights into layer3.4.conv3.weight\n",
      "Copying weights into layer3.4.bn3.running_mean\n",
      "Copying weights into layer3.4.bn3.running_var\n",
      "Copying weights into layer3.4.bn3.weight\n",
      "Copying weights into layer3.4.bn3.bias\n",
      "Copying weights into layer3.5.conv1.weight\n",
      "Copying weights into layer3.5.bn1.running_mean\n",
      "Copying weights into layer3.5.bn1.running_var\n",
      "Copying weights into layer3.5.bn1.weight\n",
      "Copying weights into layer3.5.bn1.bias\n",
      "Copying weights into layer3.5.conv2.weight\n",
      "Copying weights into layer3.5.bn2.running_mean\n",
      "Copying weights into layer3.5.bn2.running_var\n",
      "Copying weights into layer3.5.bn2.weight\n",
      "Copying weights into layer3.5.bn2.bias\n",
      "Copying weights into layer3.5.conv3.weight\n",
      "Copying weights into layer3.5.bn3.running_mean\n",
      "Copying weights into layer3.5.bn3.running_var\n",
      "Copying weights into layer3.5.bn3.weight\n",
      "Copying weights into layer3.5.bn3.bias\n",
      "Copying weights into layer3.6.conv1.weight\n",
      "Copying weights into layer3.6.bn1.running_mean\n",
      "Copying weights into layer3.6.bn1.running_var\n",
      "Copying weights into layer3.6.bn1.weight\n",
      "Copying weights into layer3.6.bn1.bias\n",
      "Copying weights into layer3.6.conv2.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying weights into layer3.6.bn2.running_mean\n",
      "Copying weights into layer3.6.bn2.running_var\n",
      "Copying weights into layer3.6.bn2.weight\n",
      "Copying weights into layer3.6.bn2.bias\n",
      "Copying weights into layer3.6.conv3.weight\n",
      "Copying weights into layer3.6.bn3.running_mean\n",
      "Copying weights into layer3.6.bn3.running_var\n",
      "Copying weights into layer3.6.bn3.weight\n",
      "Copying weights into layer3.6.bn3.bias\n",
      "Copying weights into layer3.7.conv1.weight\n",
      "Copying weights into layer3.7.bn1.running_mean\n",
      "Copying weights into layer3.7.bn1.running_var\n",
      "Copying weights into layer3.7.bn1.weight\n",
      "Copying weights into layer3.7.bn1.bias\n",
      "Copying weights into layer3.7.conv2.weight\n",
      "Copying weights into layer3.7.bn2.running_mean\n",
      "Copying weights into layer3.7.bn2.running_var\n",
      "Copying weights into layer3.7.bn2.weight\n",
      "Copying weights into layer3.7.bn2.bias\n",
      "Copying weights into layer3.7.conv3.weight\n",
      "Copying weights into layer3.7.bn3.running_mean\n",
      "Copying weights into layer3.7.bn3.running_var\n",
      "Copying weights into layer3.7.bn3.weight\n",
      "Copying weights into layer3.7.bn3.bias\n",
      "Copying weights into layer3.8.conv1.weight\n",
      "Copying weights into layer3.8.bn1.running_mean\n",
      "Copying weights into layer3.8.bn1.running_var\n",
      "Copying weights into layer3.8.bn1.weight\n",
      "Copying weights into layer3.8.bn1.bias\n",
      "Copying weights into layer3.8.conv2.weight\n",
      "Copying weights into layer3.8.bn2.running_mean\n",
      "Copying weights into layer3.8.bn2.running_var\n",
      "Copying weights into layer3.8.bn2.weight\n",
      "Copying weights into layer3.8.bn2.bias\n",
      "Copying weights into layer3.8.conv3.weight\n",
      "Copying weights into layer3.8.bn3.running_mean\n",
      "Copying weights into layer3.8.bn3.running_var\n",
      "Copying weights into layer3.8.bn3.weight\n",
      "Copying weights into layer3.8.bn3.bias\n",
      "Copying weights into layer3.9.conv1.weight\n",
      "Copying weights into layer3.9.bn1.running_mean\n",
      "Copying weights into layer3.9.bn1.running_var\n",
      "Copying weights into layer3.9.bn1.weight\n",
      "Copying weights into layer3.9.bn1.bias\n",
      "Copying weights into layer3.9.conv2.weight\n",
      "Copying weights into layer3.9.bn2.running_mean\n",
      "Copying weights into layer3.9.bn2.running_var\n",
      "Copying weights into layer3.9.bn2.weight\n",
      "Copying weights into layer3.9.bn2.bias\n",
      "Copying weights into layer3.9.conv3.weight\n",
      "Copying weights into layer3.9.bn3.running_mean\n",
      "Copying weights into layer3.9.bn3.running_var\n",
      "Copying weights into layer3.9.bn3.weight\n",
      "Copying weights into layer3.9.bn3.bias\n",
      "Copying weights into layer3.10.conv1.weight\n",
      "Copying weights into layer3.10.bn1.running_mean\n",
      "Copying weights into layer3.10.bn1.running_var\n",
      "Copying weights into layer3.10.bn1.weight\n",
      "Copying weights into layer3.10.bn1.bias\n",
      "Copying weights into layer3.10.conv2.weight\n",
      "Copying weights into layer3.10.bn2.running_mean\n",
      "Copying weights into layer3.10.bn2.running_var\n",
      "Copying weights into layer3.10.bn2.weight\n",
      "Copying weights into layer3.10.bn2.bias\n",
      "Copying weights into layer3.10.conv3.weight\n",
      "Copying weights into layer3.10.bn3.running_mean\n",
      "Copying weights into layer3.10.bn3.running_var\n",
      "Copying weights into layer3.10.bn3.weight\n",
      "Copying weights into layer3.10.bn3.bias\n",
      "Copying weights into layer3.11.conv1.weight\n",
      "Copying weights into layer3.11.bn1.running_mean\n",
      "Copying weights into layer3.11.bn1.running_var\n",
      "Copying weights into layer3.11.bn1.weight\n",
      "Copying weights into layer3.11.bn1.bias\n",
      "Copying weights into layer3.11.conv2.weight\n",
      "Copying weights into layer3.11.bn2.running_mean\n",
      "Copying weights into layer3.11.bn2.running_var\n",
      "Copying weights into layer3.11.bn2.weight\n",
      "Copying weights into layer3.11.bn2.bias\n",
      "Copying weights into layer3.11.conv3.weight\n",
      "Copying weights into layer3.11.bn3.running_mean\n",
      "Copying weights into layer3.11.bn3.running_var\n",
      "Copying weights into layer3.11.bn3.weight\n",
      "Copying weights into layer3.11.bn3.bias\n",
      "Copying weights into layer3.12.conv1.weight\n",
      "Copying weights into layer3.12.bn1.running_mean\n",
      "Copying weights into layer3.12.bn1.running_var\n",
      "Copying weights into layer3.12.bn1.weight\n",
      "Copying weights into layer3.12.bn1.bias\n",
      "Copying weights into layer3.12.conv2.weight\n",
      "Copying weights into layer3.12.bn2.running_mean\n",
      "Copying weights into layer3.12.bn2.running_var\n",
      "Copying weights into layer3.12.bn2.weight\n",
      "Copying weights into layer3.12.bn2.bias\n",
      "Copying weights into layer3.12.conv3.weight\n",
      "Copying weights into layer3.12.bn3.running_mean\n",
      "Copying weights into layer3.12.bn3.running_var\n",
      "Copying weights into layer3.12.bn3.weight\n",
      "Copying weights into layer3.12.bn3.bias\n",
      "Copying weights into layer3.13.conv1.weight\n",
      "Copying weights into layer3.13.bn1.running_mean\n",
      "Copying weights into layer3.13.bn1.running_var\n",
      "Copying weights into layer3.13.bn1.weight\n",
      "Copying weights into layer3.13.bn1.bias\n",
      "Copying weights into layer3.13.conv2.weight\n",
      "Copying weights into layer3.13.bn2.running_mean\n",
      "Copying weights into layer3.13.bn2.running_var\n",
      "Copying weights into layer3.13.bn2.weight\n",
      "Copying weights into layer3.13.bn2.bias\n",
      "Copying weights into layer3.13.conv3.weight\n",
      "Copying weights into layer3.13.bn3.running_mean\n",
      "Copying weights into layer3.13.bn3.running_var\n",
      "Copying weights into layer3.13.bn3.weight\n",
      "Copying weights into layer3.13.bn3.bias\n",
      "Copying weights into layer3.14.conv1.weight\n",
      "Copying weights into layer3.14.bn1.running_mean\n",
      "Copying weights into layer3.14.bn1.running_var\n",
      "Copying weights into layer3.14.bn1.weight\n",
      "Copying weights into layer3.14.bn1.bias\n",
      "Copying weights into layer3.14.conv2.weight\n",
      "Copying weights into layer3.14.bn2.running_mean\n",
      "Copying weights into layer3.14.bn2.running_var\n",
      "Copying weights into layer3.14.bn2.weight\n",
      "Copying weights into layer3.14.bn2.bias\n",
      "Copying weights into layer3.14.conv3.weight\n",
      "Copying weights into layer3.14.bn3.running_mean\n",
      "Copying weights into layer3.14.bn3.running_var\n",
      "Copying weights into layer3.14.bn3.weight\n",
      "Copying weights into layer3.14.bn3.bias\n",
      "Copying weights into layer3.15.conv1.weight\n",
      "Copying weights into layer3.15.bn1.running_mean\n",
      "Copying weights into layer3.15.bn1.running_var\n",
      "Copying weights into layer3.15.bn1.weight\n",
      "Copying weights into layer3.15.bn1.bias\n",
      "Copying weights into layer3.15.conv2.weight\n",
      "Copying weights into layer3.15.bn2.running_mean\n",
      "Copying weights into layer3.15.bn2.running_var\n",
      "Copying weights into layer3.15.bn2.weight\n",
      "Copying weights into layer3.15.bn2.bias\n",
      "Copying weights into layer3.15.conv3.weight\n",
      "Copying weights into layer3.15.bn3.running_mean\n",
      "Copying weights into layer3.15.bn3.running_var\n",
      "Copying weights into layer3.15.bn3.weight\n",
      "Copying weights into layer3.15.bn3.bias\n",
      "Copying weights into layer3.16.conv1.weight\n",
      "Copying weights into layer3.16.bn1.running_mean\n",
      "Copying weights into layer3.16.bn1.running_var\n",
      "Copying weights into layer3.16.bn1.weight\n",
      "Copying weights into layer3.16.bn1.bias\n",
      "Copying weights into layer3.16.conv2.weight\n",
      "Copying weights into layer3.16.bn2.running_mean\n",
      "Copying weights into layer3.16.bn2.running_var\n",
      "Copying weights into layer3.16.bn2.weight\n",
      "Copying weights into layer3.16.bn2.bias\n",
      "Copying weights into layer3.16.conv3.weight\n",
      "Copying weights into layer3.16.bn3.running_mean\n",
      "Copying weights into layer3.16.bn3.running_var\n",
      "Copying weights into layer3.16.bn3.weight\n",
      "Copying weights into layer3.16.bn3.bias\n",
      "Copying weights into layer3.17.conv1.weight\n",
      "Copying weights into layer3.17.bn1.running_mean\n",
      "Copying weights into layer3.17.bn1.running_var\n",
      "Copying weights into layer3.17.bn1.weight\n",
      "Copying weights into layer3.17.bn1.bias\n",
      "Copying weights into layer3.17.conv2.weight\n",
      "Copying weights into layer3.17.bn2.running_mean\n",
      "Copying weights into layer3.17.bn2.running_var\n",
      "Copying weights into layer3.17.bn2.weight\n",
      "Copying weights into layer3.17.bn2.bias\n",
      "Copying weights into layer3.17.conv3.weight\n",
      "Copying weights into layer3.17.bn3.running_mean\n",
      "Copying weights into layer3.17.bn3.running_var\n",
      "Copying weights into layer3.17.bn3.weight\n",
      "Copying weights into layer3.17.bn3.bias\n",
      "Copying weights into layer3.18.conv1.weight\n",
      "Copying weights into layer3.18.bn1.running_mean\n",
      "Copying weights into layer3.18.bn1.running_var\n",
      "Copying weights into layer3.18.bn1.weight\n",
      "Copying weights into layer3.18.bn1.bias\n",
      "Copying weights into layer3.18.conv2.weight\n",
      "Copying weights into layer3.18.bn2.running_mean\n",
      "Copying weights into layer3.18.bn2.running_var\n",
      "Copying weights into layer3.18.bn2.weight\n",
      "Copying weights into layer3.18.bn2.bias\n",
      "Copying weights into layer3.18.conv3.weight\n",
      "Copying weights into layer3.18.bn3.running_mean\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying weights into layer3.18.bn3.running_var\n",
      "Copying weights into layer3.18.bn3.weight\n",
      "Copying weights into layer3.18.bn3.bias\n",
      "Copying weights into layer3.19.conv1.weight\n",
      "Copying weights into layer3.19.bn1.running_mean\n",
      "Copying weights into layer3.19.bn1.running_var\n",
      "Copying weights into layer3.19.bn1.weight\n",
      "Copying weights into layer3.19.bn1.bias\n",
      "Copying weights into layer3.19.conv2.weight\n",
      "Copying weights into layer3.19.bn2.running_mean\n",
      "Copying weights into layer3.19.bn2.running_var\n",
      "Copying weights into layer3.19.bn2.weight\n",
      "Copying weights into layer3.19.bn2.bias\n",
      "Copying weights into layer3.19.conv3.weight\n",
      "Copying weights into layer3.19.bn3.running_mean\n",
      "Copying weights into layer3.19.bn3.running_var\n",
      "Copying weights into layer3.19.bn3.weight\n",
      "Copying weights into layer3.19.bn3.bias\n",
      "Copying weights into layer3.20.conv1.weight\n",
      "Copying weights into layer3.20.bn1.running_mean\n",
      "Copying weights into layer3.20.bn1.running_var\n",
      "Copying weights into layer3.20.bn1.weight\n",
      "Copying weights into layer3.20.bn1.bias\n",
      "Copying weights into layer3.20.conv2.weight\n",
      "Copying weights into layer3.20.bn2.running_mean\n",
      "Copying weights into layer3.20.bn2.running_var\n",
      "Copying weights into layer3.20.bn2.weight\n",
      "Copying weights into layer3.20.bn2.bias\n",
      "Copying weights into layer3.20.conv3.weight\n",
      "Copying weights into layer3.20.bn3.running_mean\n",
      "Copying weights into layer3.20.bn3.running_var\n",
      "Copying weights into layer3.20.bn3.weight\n",
      "Copying weights into layer3.20.bn3.bias\n",
      "Copying weights into layer3.21.conv1.weight\n",
      "Copying weights into layer3.21.bn1.running_mean\n",
      "Copying weights into layer3.21.bn1.running_var\n",
      "Copying weights into layer3.21.bn1.weight\n",
      "Copying weights into layer3.21.bn1.bias\n",
      "Copying weights into layer3.21.conv2.weight\n",
      "Copying weights into layer3.21.bn2.running_mean\n",
      "Copying weights into layer3.21.bn2.running_var\n",
      "Copying weights into layer3.21.bn2.weight\n",
      "Copying weights into layer3.21.bn2.bias\n",
      "Copying weights into layer3.21.conv3.weight\n",
      "Copying weights into layer3.21.bn3.running_mean\n",
      "Copying weights into layer3.21.bn3.running_var\n",
      "Copying weights into layer3.21.bn3.weight\n",
      "Copying weights into layer3.21.bn3.bias\n",
      "Copying weights into layer3.22.conv1.weight\n",
      "Copying weights into layer3.22.bn1.running_mean\n",
      "Copying weights into layer3.22.bn1.running_var\n",
      "Copying weights into layer3.22.bn1.weight\n",
      "Copying weights into layer3.22.bn1.bias\n",
      "Copying weights into layer3.22.conv2.weight\n",
      "Copying weights into layer3.22.bn2.running_mean\n",
      "Copying weights into layer3.22.bn2.running_var\n",
      "Copying weights into layer3.22.bn2.weight\n",
      "Copying weights into layer3.22.bn2.bias\n",
      "Copying weights into layer3.22.conv3.weight\n",
      "Copying weights into layer3.22.bn3.running_mean\n",
      "Copying weights into layer3.22.bn3.running_var\n",
      "Copying weights into layer3.22.bn3.weight\n",
      "Copying weights into layer3.22.bn3.bias\n",
      "Copying weights into layer4.0.conv1.weight\n",
      "Copying weights into layer4.0.bn1.running_mean\n",
      "Copying weights into layer4.0.bn1.running_var\n",
      "Copying weights into layer4.0.bn1.weight\n",
      "Copying weights into layer4.0.bn1.bias\n",
      "Copying weights into layer4.0.conv2.weight\n",
      "Copying weights into layer4.0.bn2.running_mean\n",
      "Copying weights into layer4.0.bn2.running_var\n",
      "Copying weights into layer4.0.bn2.weight\n",
      "Copying weights into layer4.0.bn2.bias\n",
      "Copying weights into layer4.0.conv3.weight\n",
      "Copying weights into layer4.0.bn3.running_mean\n",
      "Copying weights into layer4.0.bn3.running_var\n",
      "Copying weights into layer4.0.bn3.weight\n",
      "Copying weights into layer4.0.bn3.bias\n",
      "Copying weights into layer4.0.downsample.0.weight\n",
      "Copying weights into layer4.0.downsample.1.running_mean\n",
      "Copying weights into layer4.0.downsample.1.running_var\n",
      "Copying weights into layer4.0.downsample.1.weight\n",
      "Copying weights into layer4.0.downsample.1.bias\n",
      "Copying weights into layer4.1.conv1.weight\n",
      "Copying weights into layer4.1.bn1.running_mean\n",
      "Copying weights into layer4.1.bn1.running_var\n",
      "Copying weights into layer4.1.bn1.weight\n",
      "Copying weights into layer4.1.bn1.bias\n",
      "Copying weights into layer4.1.conv2.weight\n",
      "Copying weights into layer4.1.bn2.running_mean\n",
      "Copying weights into layer4.1.bn2.running_var\n",
      "Copying weights into layer4.1.bn2.weight\n",
      "Copying weights into layer4.1.bn2.bias\n",
      "Copying weights into layer4.1.conv3.weight\n",
      "Copying weights into layer4.1.bn3.running_mean\n",
      "Copying weights into layer4.1.bn3.running_var\n",
      "Copying weights into layer4.1.bn3.weight\n",
      "Copying weights into layer4.1.bn3.bias\n",
      "Copying weights into layer4.2.conv1.weight\n",
      "Copying weights into layer4.2.bn1.running_mean\n",
      "Copying weights into layer4.2.bn1.running_var\n",
      "Copying weights into layer4.2.bn1.weight\n",
      "Copying weights into layer4.2.bn1.bias\n",
      "Copying weights into layer4.2.conv2.weight\n",
      "Copying weights into layer4.2.bn2.running_mean\n",
      "Copying weights into layer4.2.bn2.running_var\n",
      "Copying weights into layer4.2.bn2.weight\n",
      "Copying weights into layer4.2.bn2.bias\n",
      "Copying weights into layer4.2.conv3.weight\n",
      "Copying weights into layer4.2.bn3.running_mean\n",
      "Copying weights into layer4.2.bn3.running_var\n",
      "Copying weights into layer4.2.bn3.weight\n",
      "Copying weights into layer4.2.bn3.bias\n",
      "Weight dimensions mismatch for fc.weight\n",
      "Weight dimensions mismatch for fc.bias\n"
     ]
    }
   ],
   "source": [
    "state_dict = load_state_dict_from_url(net_ucf11.model_urls['resnet101'], progress = True)\n",
    "for k,par in state_dict.items():    \n",
    "    if k in feature_extractor_base.state_dict().keys() and par.size() == feature_extractor_base.state_dict()[k].size():\n",
    "        feature_extractor_base.state_dict()[k].copy_(par)\n",
    "        print(\"Copying weights into {}\".format(k))\n",
    "    else:\n",
    "        print(\"Weight dimensions mismatch for {}\".format(k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2eb0c64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor_base = feature_extractor_base.to(device)\n",
    "rnn = rnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "15e8cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load images and label\n",
    "def load_data(stage, image_size = 128):\n",
    "    # all data here\n",
    "    if stage == \"train\":\n",
    "        source_dir = 'ucf11_train_data/data'\n",
    "\n",
    "    # list of folders with videos: 1,2,\n",
    "    # image transform\n",
    "    # Resize transform takes a Pillow image object\n",
    "    transform_train_img = transforms.Compose([\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.CenterCrop(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])])\n",
    "    # select frames\n",
    "    # this will be the dimensions of one data point, \n",
    "    # seq_length x H x W\n",
    "    min_frame = 0\n",
    "    max_frame = 50\n",
    "    seq_length = max_frame - min_frame\n",
    "    params = {'batch_size':sample_size, 'shuffle':True}\n",
    "    # this will return the data for ONE video\n",
    "    data_point = dataset_ucf11.DatasetUCF11(source_dir, seq_length, transform_train_img)\n",
    "    dataset = data.DataLoader(data_point, **params)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cecbcf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_convnet_lstm():\n",
    "    # set both networks to train mode\n",
    "    # get data, instantiated only once \n",
    "    train_data = load_data(\"train\")    \n",
    "    model_params = list(feature_extractor_base.parameters())+list(rnn.parameters())\n",
    "    feature_extractor_base.train()\n",
    "    rnn.train()\n",
    "    optimizer = torch.optim.Adam(model_params, lr=learning_rate)\n",
    "    # softmax + loglikelihood\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    loss_function = loss_function.to(device)\n",
    "    loss_hist = []\n",
    "    for e in range(epoch):\n",
    "        print ('Current epoch = {0:d}'.format(e))\n",
    "        total_loss = 0  \n",
    "        optimizer.zero_grad()\n",
    "        for idx, X, y in train_data:\n",
    "            optimizer.zero_grad()            \n",
    "            X, y = X.to(device), y.to(device) \n",
    "            output = rnn(feature_extractor_base(X))\n",
    "            loss = loss_function(output, y.view(-1)) \n",
    "            loss_hist.append(loss)\n",
    "            # increment epoch loss\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # average loss this epoch, divide by the number of batches in the dataset\n",
    "        total_loss = total_loss/len(train_data)\n",
    "        loss_hist.append(total_loss)\n",
    "        print('Total loss for epoch {0:} = {1:.3f}'.format(e, total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc67c287",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_convnet_lstm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7bfb69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
